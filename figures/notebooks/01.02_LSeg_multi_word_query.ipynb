{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from core.integrate import FeatureFusionScalableTSDFVolume\n",
    "from core.dataset import ScanNet\n",
    "from core.labeler import CLIPTextQuerier, KMeansLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3d._build_config[\"ENABLE_HEADLESS_RENDERING\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ScanNet('/home/quanta/Datasets/ScanNet/')\n",
    "nyu40_color = dataset.nyu40id_to_color\n",
    "nyu40_class = [dataset.nyu40_id_to_class[i] for i in range(41)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = \"scannet_scene0000_00\"\n",
    "save_dir = \"/storage/quanta/Experiments/feature-instance-fusion/\" + scene + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_pth = os.path.abspath(\"../../config/views/\" + scene + \".json\")\n",
    "with open(json_pth, \"r\") as f:\n",
    "    views = json.load(f)['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdf_device = \"cuda:1\"\n",
    "tsdf_volume = FeatureFusionScalableTSDFVolume(\n",
    "    voxel_size=0.015,\n",
    "    sdf_trunc=0.075,\n",
    "    margin=0.08,\n",
    "    device=\"cuda:1\",\n",
    ")\n",
    "tsdf_volume.load(save_dir + \"tsdf/tsdf_volume_unpruned.pt\")\n",
    "verts = np.load(save_dir + \"tsdf/verts.npy\")\n",
    "faces = np.load(save_dir + \"tsdf/faces.npy\")\n",
    "tsdf_volume.load_feats(save_dir + \"tsdf_feature_lseg/feats.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts_feats = tsdf_volume.extract_feat_on_grid(verts=verts, device='cpu')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_querier = CLIPTextQuerier(device='cuda:1')\n",
    "clip_querier.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clip_querier.multi_text_query(\n",
    "    texts=nyu40_class,\n",
    "    img_feats=torch.from_numpy(verts_feats),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = o3d.geometry.TriangleMesh(\n",
    "    vertices=o3d.utility.Vector3dVector(verts),\n",
    "    triangles=o3d.utility.Vector3iVector(faces),\n",
    ")\n",
    "mesh.compute_vertex_normals()\n",
    "color = nyu40_color[labels] / 255\n",
    "mesh.vertex_colors = o3d.utility.Vector3dVector(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"../01_LSeg/02_nyu40_multi_class_query/\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, view in enumerate(views):\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(mesh)\n",
    "    vis.set_view_status(json.dumps(view[\"view\"]))\n",
    "    buffer = vis.capture_screen_float_buffer(do_render=True)\n",
    "    image = Image.fromarray((np.asarray(buffer) * 255).astype(np.uint8))\n",
    "    # display(image)\n",
    "    image.save(save_dir + \"{:02d}_\".format(i) + view[\"tag\"] + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to ground truth vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ScanNet(\"/home/quanta/Datasets/ScanNet/\")\n",
    "scan_id = \"scene0000_00\"\n",
    "id = dataset.scan_id_list.index(scan_id)\n",
    "single_instance = dataset[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts = single_instance[\"vertices\"]\n",
    "faces = single_instance[\"faces\"]\n",
    "gt_labels = single_instance[\"ground_truth_labels\"]\n",
    "verts_feats = tsdf_volume.extract_feat_on_grid(verts=verts, device='cpu')[0]\n",
    "labels = clip_querier.multi_text_query(\n",
    "    texts=nyu40_class,\n",
    "    img_feats=torch.from_numpy(verts_feats),\n",
    ").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unknown': 7.680285778075463,\n",
       " 'wall': 62.62359090622836,\n",
       " 'chair': 0.0,\n",
       " 'books': 0.0,\n",
       " 'floor': 57.099949941598524,\n",
       " 'door': 28.727434811678183,\n",
       " 'otherprop': 0.0,\n",
       " 'window': 54.7700754975978,\n",
       " 'table': 17.768311117218634,\n",
       " 'otherfurniture': 0.0,\n",
       " 'pillow': 0.0,\n",
       " 'picture': 0.0,\n",
       " 'ceiling': 73.85645221271848,\n",
       " 'box': 0.0,\n",
       " 'cabinet': 45.34689540003036,\n",
       " 'desk': 0.0,\n",
       " 'shelves': 2.007057785619762,\n",
       " 'towel': 0.0,\n",
       " 'sofa': 79.50922443130933,\n",
       " 'sink': 35.960591133004925,\n",
       " 'lamp': 0.0,\n",
       " 'bed': 61.720554272517326,\n",
       " 'bookshelf': 0.0,\n",
       " 'mirror': 15.853658536585366,\n",
       " 'curtain': 59.18951132300357,\n",
       " 'whiteboard': 0.0,\n",
       " 'toilet': 39.157706093189965,\n",
       " 'bag': 0.0,\n",
       " 'clothes': 0.0,\n",
       " 'night stand': 0.0,\n",
       " 'television': 37.138621200889546,\n",
       " 'dresser': 0.0,\n",
       " 'refridgerator': 69.22060766182298,\n",
       " 'shower curtain': 0.0,\n",
       " 'bathtub': 0.0,\n",
       " 'counter': 25.511811023622048,\n",
       " 'otherstructure': 0.0,\n",
       " 'floor mat': 0.0,\n",
       " 'paper': 0.0,\n",
       " 'person': 0.0,\n",
       " 'blinds': 0.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_gt = np.zeros((gt_labels.size, 41), dtype=np.int32)\n",
    "one_hot_gt[np.arange(gt_labels.size), gt_labels] = 1\n",
    "\n",
    "one_hot_pred = np.zeros((labels.size, 41), dtype=np.int32)\n",
    "one_hot_pred[np.arange(labels.size), labels] = 1\n",
    "\n",
    "tp = ((one_hot_gt == one_hot_pred) * one_hot_pred).sum(axis=0)\n",
    "fp = ((one_hot_gt != one_hot_pred) * one_hot_pred).sum(axis=0)\n",
    "fn = ((one_hot_gt != one_hot_pred) * (1 - one_hot_pred)).sum(axis=0)\n",
    "miou = tp / (tp + fp + fn + 1e-16)\n",
    "mIoU = {}\n",
    "for cls in dataset.nyu40_id_to_class.keys():\n",
    "    mIoU[dataset.nyu40_id_to_class[cls]] = miou[cls] * 100\n",
    "mIoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compared to ground truth labels in finer vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/storage/quanta/Experiments/feature-instance-fusion/\" + scene + \"/\"\n",
    "\n",
    "verts = np.load(save_dir + \"tsdf/verts.npy\")\n",
    "faces = np.load(save_dir + \"tsdf/faces.npy\")\n",
    "verts_feats = tsdf_volume.extract_feat_on_grid(verts=verts, device='cpu')[0]\n",
    "labels = clip_querier.multi_text_query(\n",
    "    texts=nyu40_class,\n",
    "    img_feats=torch.from_numpy(verts_feats),\n",
    ").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdf_volume.load_feats(save_dir + 'tsdf_feature_gt_semantic/feats.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_score = tsdf_volume.extract_feat_on_grid(verts=verts)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = np.argmax(gt_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unknown': 0.0,\n",
       " 'wall': 66.55031065279276,\n",
       " 'chair': 0.0,\n",
       " 'books': 0.0,\n",
       " 'floor': 61.54319686768637,\n",
       " 'door': 22.666771061697464,\n",
       " 'otherprop': 0.0,\n",
       " 'window': 46.198402536430706,\n",
       " 'table': 16.35894983613058,\n",
       " 'otherfurniture': 0.0,\n",
       " 'pillow': 0.0,\n",
       " 'picture': 0.0,\n",
       " 'ceiling': 86.85286513138115,\n",
       " 'box': 0.0,\n",
       " 'cabinet': 40.47151852394201,\n",
       " 'desk': 0.0,\n",
       " 'shelves': 3.3074186322308603,\n",
       " 'towel': 0.0,\n",
       " 'sofa': 76.32380905943732,\n",
       " 'sink': 25.971004116699483,\n",
       " 'lamp': 0.0,\n",
       " 'bed': 72.00018896447467,\n",
       " 'bookshelf': 0.0,\n",
       " 'mirror': 8.730847065625904,\n",
       " 'curtain': 60.89980185710401,\n",
       " 'whiteboard': 0.0,\n",
       " 'toilet': 35.92628051699378,\n",
       " 'bag': 0.0,\n",
       " 'clothes': 0.0,\n",
       " 'night stand': 0.0,\n",
       " 'television': 41.128127527459625,\n",
       " 'dresser': 0.0,\n",
       " 'refridgerator': 79.79410388394946,\n",
       " 'shower curtain': 0.0,\n",
       " 'bathtub': 0.0,\n",
       " 'counter': 31.92039978582902,\n",
       " 'otherstructure': 0.0,\n",
       " 'floor mat': 0.0,\n",
       " 'paper': 0.0,\n",
       " 'person': 0.0,\n",
       " 'blinds': 0.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "one_hot_gt = np.zeros((gt_labels.size, 41), dtype=np.int32)\n",
    "one_hot_gt[np.arange(gt_labels.size), gt_labels] = 1\n",
    "\n",
    "one_hot_pred = np.zeros((labels.size, 41), dtype=np.int32)\n",
    "one_hot_pred[np.arange(labels.size), labels] = 1\n",
    "\n",
    "tp = ((one_hot_gt == one_hot_pred) * one_hot_pred).sum(axis=0)\n",
    "fp = ((one_hot_gt != one_hot_pred) * one_hot_pred).sum(axis=0)\n",
    "fn = ((one_hot_gt != one_hot_pred) * (1 - one_hot_pred)).sum(axis=0)\n",
    "miou = tp / (tp + fp + fn + 1e-16)\n",
    "mIoU = {}\n",
    "for cls in dataset.nyu40_id_to_class.keys():\n",
    "    mIoU[dataset.nyu40_id_to_class[cls]] = miou[cls] * 100\n",
    "mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
